{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/45664104/86419986-e932eb00-bccc-11ea-98e3-e1dcba512804.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_PATH = \"../datasets/supervisely\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Cloning into 'supervisely-to-darknet'...\n"
    }
   ],
   "source": [
    "# Clone the repo which contains essential functions\n",
    "!git clone https://github.com/JinhangZhu/supervisely-to-darknet.git\n",
    "import sys\n",
    "sys.path.append('./supervisely-to-darknet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from convert import get_classes\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Person: 100%|██████████| 21/21 [00:00<00:00, 21472.55it/s]\n"
    }
   ],
   "source": [
    "# Delete all separate classes.names within each person dataset\n",
    "for p in tqdm(os.listdir(DS_PATH), desc='Person'):\n",
    "    filepath = os.path.join(DS_PATH, p)\n",
    "    if os.path.isdir(filepath):\n",
    "        if os.path.isfile(filepath + './classes.names'):\n",
    "            os.remove(filepath + './classes.names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nSave labels for person/subset/images in ./ds_class_names.json.\nP01 :['hand', '1', 'left_hand', 'right_hand']\nP02 :['hand']\nP03 :['hand']\nP04 :['hand']\nP05 :['hand']\nP06 :['hand']\nP07 :['hand']\nP08 :['hand']\nP10 :['hand']\nP12 :['hand']\nP13 :['hand']\nP14 :['hand']\nP15 :['hand']\nP16 :['hand']\nP17 :['hand']\nP19 :['hand']\nP20 :['hand']\nP21 :['hand']\nP22 :['hand']\nP23 :['hand']\n"
    }
   ],
   "source": [
    "class_names = {}    # Class names for person\n",
    "\n",
    "for p in os.listdir(DS_PATH):\n",
    "    filepath = os.path.join(DS_PATH, p)\n",
    "    # print('\\nPerson {}: '.format(p), filepath)\n",
    "\n",
    "    if os.path.isdir(filepath):\n",
    "        # Read meta.json to get classes\n",
    "        meta_path = filepath + os.sep + 'meta.json'\n",
    "        if os.path.isfile(meta_path):\n",
    "            classes, names_path = get_classes(meta_path, write=False)\n",
    "            class_names[p] = classes\n",
    "        else:\n",
    "            print('There is no meta.json file for person ', p)\n",
    "\n",
    "# Save class names of all datasets into json\n",
    "# class_names_path = DS_PATH + './ds_class_names.json'\n",
    "class_names_path = './ds_class_names.json'\n",
    "print('\\nSave labels for person/subset/images in {}.'.format(class_names_path))\n",
    "with open(class_names_path, 'w') as fp:\n",
    "    json.dump(class_names, fp, indent=4)\n",
    "\n",
    "# Iterate over key/value pairs in dict and print them\n",
    "for p, clss in class_names.items():\n",
    "    print(p, ' : ', clss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出来，整体的标注信息表明，这20个人的数据集里，只有第一个人的数据包含四种标签，其余所有人的数据都是只有`hand`的标签，也就是有手和无手的区别。\n",
    "下一步看：\n",
    "\n",
    "- 各个标签的数目/该数据集的**有**标注总数/照片总数\n",
    "\n",
    "> 但是`1`这个标签实在是很奇怪，需要继续看。对于左右手的标签，我随便点开了几个标注文件，发现没有左右手的，可能也是个占小部分的标注，也需要拿出来看看，是哪些照片有这些小比例的标注，这个比例有多少？总数又是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read json of class names\n",
    "# with open(class_names_path, 'r') as fp:\n",
    "#     class_names = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_labels(sub_p_path):\n",
    "    \"\"\"Get the labels from a subset of a person.\n",
    "\n",
    "    Argument:\n",
    "        sub_p_path: the path of the subset. e.g. '../datasets/supervisely\\\\P23\\\\P23_01'\n",
    "    \n",
    "    Returns:\n",
    "        sub_p_labels: a dictionary whose keys are image names, values are a list of tuples.\n",
    "            Each tuple is a bounding box: (class_name, b_x_center, b_y_center, b_width, b_height)\n",
    "    \"\"\"\n",
    "    sub_p_labels={}\n",
    "\n",
    "    # Get all file real paths\n",
    "    read_path = sub_p_path + os.sep\n",
    "    ann_paths = sorted(glob.glob(read_path + 'ann/' + '*.json'))\n",
    "    img_paths = sorted(glob.glob(read_path + 'img/' + '*.jpg'))\n",
    "\n",
    "    # Import all json annotation files for images\n",
    "    for (ann_path, img_path) in zip(ann_paths, img_paths):\n",
    "        # Current image\n",
    "        img_name = os.path.basename(img_path)[:-4]\n",
    "        sub_p_labels[img_name] = []\n",
    "\n",
    "        # Import json\n",
    "        with open(ann_path) as ann_f:\n",
    "            ann_data = json.load(ann_f)\n",
    "        \n",
    "        # Image size\n",
    "        image_size = ann_data['size']   # dict: {'height': , 'width': }\n",
    "\n",
    "        # Objects bounding boxes\n",
    "        bboxes = ann_data['objects']\n",
    "        if len(bboxes) != 0:    # With object(s)\n",
    "            for bbox in bboxes:\n",
    "                class_name = bbox['classTitle']\n",
    "                corner_coords = bbox['points']['exterior']  # bbox corner coordinates in [[left, top], [right, bottom]]\n",
    "\n",
    "                # Normalisation\n",
    "                b_x_center = (corner_coords[0][0] + corner_coords[1][0]) / 2 / image_size['width']\n",
    "                b_y_center = (corner_coords[0][1] + corner_coords[1][1]) / 2 / image_size['height']\n",
    "                b_width = (corner_coords[1][0] - corner_coords[0][0]) / image_size['width']\n",
    "                b_height = (corner_coords[1][1] - corner_coords[0][1]) / image_size['height']\n",
    "\n",
    "                # Save bbox label as a tuple for the image\n",
    "                sub_p_labels[img_name].append(\n",
    "                    (\n",
    "                        class_name,\n",
    "                        round(b_x_center, 6),\n",
    "                        round(b_y_center, 6),\n",
    "                        round(b_width, 6),\n",
    "                        round(b_height, 6)\n",
    "                    )\n",
    "                ) \n",
    "\n",
    "                # # Check the annotation\n",
    "                # if class_name == '1':\n",
    "                #     print('label \"1\": {}'.format(img_path))\n",
    "                # elif class_name == 'left_hand':\n",
    "                #     print('label \"left_hand\": {}'.format(img_path))\n",
    "                # elif class_name == 'right_hand':\n",
    "                #     print('label \"right_hand\": {}'.format(img_path))\n",
    "                # else:\n",
    "                #     pass\n",
    "        \n",
    "    return sub_p_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Person:   0%|          | 0/21 [00:00<?, ?it/s]1004 image-annotation pairs in subset P01_02 of person P01\n238 image-annotation pairs in subset P01_03 of person P01\n984 image-annotation pairs in subset P01_06 of person P01\nPerson:  10%|▉         | 2/21 [00:00<00:03,  5.91it/s]2070 image-annotation pairs in subset P02_06 of person P02\n134 image-annotation pairs in subset P02_08 of person P02\n109 image-annotation pairs in subset P02_11 of person P02\nPerson:  14%|█▍        | 3/21 [00:00<00:03,  4.68it/s]219 image-annotation pairs in subset P03_06 of person P03\n215 image-annotation pairs in subset P03_07 of person P03\n106 image-annotation pairs in subset P03_11 of person P03\n49 image-annotation pairs in subset P03_18 of person P03\n195 image-annotation pairs in subset P03_27 of person P03\nPerson:  19%|█▉        | 4/21 [00:00<00:03,  4.81it/s]394 image-annotation pairs in subset P04_21 of person P04\n777 image-annotation pairs in subset P05_04 of person P05\n312 image-annotation pairs in subset P05_05 of person P05\nPerson:  29%|██▊       | 6/21 [00:01<00:02,  5.25it/s]181 image-annotation pairs in subset P06_01 of person P06\n28 image-annotation pairs in subset P06_02 of person P06\n1371 image-annotation pairs in subset P06_03 of person P06\n62 image-annotation pairs in subset P06_08 of person P06\nPerson:  33%|███▎      | 7/21 [00:01<00:02,  4.67it/s]224 image-annotation pairs in subset P07_02 of person P07\n346 image-annotation pairs in subset P07_08 of person P07\n447 image-annotation pairs in subset P07_11 of person P07\nPerson:  38%|███▊      | 8/21 [00:01<00:02,  4.77it/s]215 image-annotation pairs in subset P08_02 of person P08\n300 image-annotation pairs in subset P08_03 of person P08\n48 image-annotation pairs in subset P08_07 of person P08\n68 image-annotation pairs in subset P08_12 of person P08\n275 image-annotation pairs in subset P08_19 of person P08\nPerson:  43%|████▎     | 9/21 [00:01<00:02,  4.76it/s]1824 image-annotation pairs in subset P10_01 of person P10\nPerson:  48%|████▊     | 10/21 [00:02<00:02,  4.53it/s]121 image-annotation pairs in subset P12_05 of person P12\n340 image-annotation pairs in subset P12_06 of person P12\n223 image-annotation pairs in subset P13_06 of person P13\nPerson:  57%|█████▋    | 12/21 [00:02<00:01,  5.83it/s]209 image-annotation pairs in subset P14_01 of person P14\n65 image-annotation pairs in subset P14_02 of person P14\n40 image-annotation pairs in subset P14_03 of person P14\n94 image-annotation pairs in subset P15_01 of person P15\n55 image-annotation pairs in subset P15_11 of person P15\n112 image-annotation pairs in subset P16_02 of person P16\n426 image-annotation pairs in subset P16_03 of person P16\nPerson:  71%|███████▏  | 15/21 [00:02<00:00,  7.14it/s]313 image-annotation pairs in subset P17_01 of person P17\n273 image-annotation pairs in subset P19_03 of person P19\nPerson:  81%|████████  | 17/21 [00:02<00:00,  8.67it/s]426 image-annotation pairs in subset P20_03 of person P20\n1138 image-annotation pairs in subset P21_04 of person P21\nPerson:  90%|█████████ | 19/21 [00:02<00:00,  8.05it/s]853 image-annotation pairs in subset P22_09 of person P22\n184 image-annotation pairs in subset P23_01 of person P23\nPerson: 100%|██████████| 21/21 [00:02<00:00,  7.03it/s]\n\nSave labels for person/subset/images in labels.json.\n"
    }
   ],
   "source": [
    "# Labels of all datasets of all person\n",
    "# format:\n",
    "# {\n",
    "#   'person':{\n",
    "#               'subset':{\n",
    "#                           'image': [(*bbox attributes)]\n",
    "#                        }                \n",
    "#            }   \n",
    "# }\n",
    "labels = {}\n",
    "\n",
    "# Collect all annotations into a single json\n",
    "for p in tqdm(os.listdir(DS_PATH), desc='Person'):\n",
    "    p_path = os.path.join(DS_PATH, p)\n",
    "\n",
    "    if os.path.isdir(p_path): \n",
    "        labels[p] = {}   # 'person'\n",
    "\n",
    "        for sub_p in os.listdir(p_path):\n",
    "            sub_p_path = os.path.join(p_path, sub_p)\n",
    "\n",
    "            if os.path.isdir(sub_p_path):\n",
    "                labels[p][sub_p] = get_subset_labels(sub_p_path)    # 'subset'\n",
    "                print(\n",
    "                    \"{} image-annotation pairs in subset {} of person {}\".format(len(labels[p][sub_p]), sub_p, p)\n",
    "                )\n",
    "\n",
    "labels_path = 'labels.json'\n",
    "print('\\nSave labels for person/subset/images in {}.'.format(labels_path))\n",
    "with open(labels_path, 'w') as fp:\n",
    "    json.dump(labels, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到少数类的标注所在的图片|以及数目|以及总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_annotation(labels, annotation):\n",
    "    r_with_anno = False\n",
    "    for p, p_labels in labels.items():\n",
    "        for sub_p, sub_p_labels in p_labels.items():\n",
    "\n",
    "            imgs_with_anno = []\n",
    "            for img_name, bboxes in sub_p_labels.items():\n",
    "                if len(bboxes) > 0:\n",
    "                    for bbox in bboxes: # bbox: tuples of five attributes\n",
    "                        if bbox[0] == annotation:\n",
    "                            imgs_with_anno.append(img_name)\n",
    "                            break\n",
    "            \n",
    "            if len(imgs_with_anno) > 0 and r_with_anno is False:\n",
    "                r_with_anno = True  # There exists such an image with such annotation\n",
    "\n",
    "            # print(\n",
    "            #     \"For subset {}, images with annotation '{}' count {}/{}.\".format(sub_p, annotation, len(imgs_with_anno), len(sub_p_labels))#,\n",
    "            # #    imgs_with_anno\n",
    "            # )\n",
    "    return r_with_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No image with annotation: 'left_hand'\nNo image with annotation: 'right_hand'\nNo image with annotation: '1'\nImage exists with annotation: 'hand'\n"
    }
   ],
   "source": [
    "# Get all labels from class_names (for all person)\n",
    "all_annotations = []\n",
    "for clss in class_names.values():\n",
    "    all_annotations.extend(clss)\n",
    "all_annotations = set(all_annotations)\n",
    "for annotation in all_annotations:\n",
    "    if not find_annotation(labels, annotation):\n",
    "        print(\"No image with annotation: '{}'\".format(annotation))\n",
    "    else:\n",
    "        print(\"Image exists with annotation: '{}'\".format(annotation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在问题很清晰了，第一个人的数据集根本没有我开始认为的少数标签：`1`, `left_hand`, `right_hand`，猜想是最开始设置了这些但是实际标注只标注了`hand`的标签。\n",
    "\n",
    "所以得到一个结论：**这一次下载的所有的数据集都只有`hand`的标签**。可以把第一个人的`meta.json`的无用标签删掉了。\n",
    "\n",
    "下一步，**数据清洗`hand`数据集，生成anchors，完成训练**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593863544646",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}